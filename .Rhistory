getwd()
if (!file.exist("data")) {dir.create("data")}
if (!file.exista("data")) {dir.create("data")}
if (!file.exists("data")) {dir.create("data")}
#download.file()
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xlsx?accessType=DOWNLOAD"
download.file(fileUrl, destfile="./data/camerad.xlsx")
download.file(fileUrl, destfile="./data/cameras.xlsx")
download.file(fileUrl, destfile="./data/cameras.xlsx")
dateDownloaded <- date()
library(xlsx)
cameraData <- read.xlsx("./data/camerad.xlsx", sheetIndex=1, header=TRUE)
head(cameraData)
download.packages(xlsx)
install.packages(xlsx)
install.packages("xlsx")
library(xlsx)
cameraData <- read.xlsx("./data/camerad.xlsx", sheetIndex=1, header=TRUE)
head(cameraData)
cameraData <- read.xlsx("./data/cameras.xlsx", sheetIndex=1, header=TRUE)
head(cameraData)
cameraData <- read.xlsx(".\\data\\cameras.xlsx", sheetIndex=1, header=TRUE)
head(cameraData)
download.file(fileUrl, destfile="./data/cameras.xlsx", method="curl")
dateDownloaded <- date()
#install.packages("xlsx")
library(xlsx)
cameraData <- read.xlsx("./data/cameras.xlsx", sheetIndex=1, header=TRUE)
head(cameraData)
cameraData <- read.xlsx("./data/cameras.xlsx", sheetIndex=1, header=TRUE)
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
data(mpg)
qplot(displ,hwy, data=mpg)
library(graphics)
install.packages("xyplot","bwplot", "levelplot")
library("bwplot")
install.packages("xyplot","bwplot","levelplot")
install.packages("xyplot")
library(datasets)
hist(airquality$Ozone)
hist(airquality$Ozone)
with(airquality,plot(Wind,Ozone))
boxplot(Ozone ~ Month, airquality, xlab="Month", ylab="Ozone")
par()
getwd()
install.packages("RMyQSL")
con = url("http:scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode=rearLines(con)
close(con)
htmlCode
htmlCode=readLines(con)
# Reading from the web - general
#Webscraping puede ser ilegal y problematico asi que cuidado
#example: Google scholar
#readlines
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode=readLines(con)
close(con)
htmlCode
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes=T)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", key="2eaf26096d68942a037b", secret="a9ba312c1badb72b02700ba7f15a4140c77b0bef")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp <- oauth_app("github", key="2eaf26096d68942a037b", secret="a9ba312c1badb72b02700ba7f15a4140c77b0bef")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
#    http://developer.github.com/v3/oauth/
oauth_endpoints("Githubapp")
# 2. Register an application at https://github.com/settings/applications;
#    Use any URL you would like for the homepage URL (http://github.com is fine)
#    and http://localhost:1410 as the callback url
#
#    Insert your client ID and secret below - if secret is omitted, it will
#    look it up in the GITHUB_CONSUMER_SECRET environmental variable.
myapp <- oauth_app("Githubapp", key="2eaf26096d68942a037b", secret="a9ba312c1badb72b02700ba7f15a4140c77b0bef")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("Githubapp"), myapp)
oauth_endpoints("Githubapp")
oauth_endpoints("github")
myapp <- oauth_app("github", key="2eaf26096d68942a037b", secret="a9ba312c1badb72b02700ba7f15a4140c77b0bef")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("httpuv")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1)) #se crea un dataframe, mas comodo
install.packages("rjson")
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1)) #se crea un dataframe, mas comodo
library("rjason")
library("rjson")
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1)) #se crea un dataframe, mas comodo
json2
# 4. Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req
)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1)) #se crea un dataframe, mas comodo
json2
library("jasonlite")
library(jasonlite)
install.packages("jsonlite")
install.packages("jsonlite")
library("jsonlite")
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1)) #se crea un dataframe, mas comodo
names(json2)
names(json2)
names(json2$releases_url)
names(json2$description)
json2$description
json2$created_at
names(json2)
json2$name
json2["name","created_at"]
json2[,c("name","created_at")]
pnorm(q = 2,mean = 0,sd = 1)
pnorm(q = 1,mean = 0,sd = 1)
pnorm(q = -1,mean = 0,sd = 1)
pnorm(q = 1.65,mean = 0,sd = 1)
1.65*75 + 1100
1.65*7.5 + 1100
pbinom(1,size = 5,prob = 0.5)
pbinom(5,size = 5,prob = 0.5)
pbinom(4,size = 5,prob = 0.5)
pbinom(3,size = 5,prob = 0.5)
pbinom(1,size = 5,prob = 0.5)
pbinom(4,size = 5,prob = 0.5)
dbinom(4,size = 5,prob = 0.5)
dbinom(5,size = 5,prob = 0.5)
dbinom(3,size = 5,prob = 0.5)
dbinom(0,size = 5,prob = 0.5)
dbinom(4,size = 5,prob = 0.5) + dbinom(4,size = 5,prob = 0.5)
dbinom(4,size = 5,prob = 0.5)
dbinom(4,size = 5,prob = 0.5) + dbinom(5,size = 5,prob = 0.5)
pnorm(q = -1, mean = 0,sd = 1)
pnorm(q = -2, mean = 0,sd = 1)
dnorm(q = 14, mean = 0,sd = 1)
dnorm(x = 1, mean = 0,sd = 1)
dnorm(x = 2, mean = 0,sd = 1)
dnorm(x = 0, mean = 0,sd = 1)
pnorm(x = 0, mean = 0,sd = 1)
pnorm(q = 0, mean = 0,sd = 1)
pnorm(q = 2, mean = 0,sd = 1)
pnorm(q = 14, mean = 14,sd = sqrt(10))
pnorm(q = 14, mean = 14,sd = sqrt(10)) - pnorm(q = 16, mean = 14,sd = sqrt(10))
pnorm(q = 16, mean = 14,sd = sqrt(10))
pnorm(q = 14, mean = 14,sd = 1) - pnorm(q = 16, mean = 14,sd = 1)
ppois(q = 10,lambda = 5)
ppois(q = 10,lambda = 15)
pnorm(q = 14, mean = 15,sd = 1) - pnorm(q = 16, mean = 15,sd = 1)
Reproducible Research - Assessment 1
====================================
```{r library.load, echo=FALSE}
library(ggplot2)
library(scales)
```
## *Abstract*
*The following document describes a brief analysis performed on data collected
from a personal activity monitoring device, as an introduction to* **Literate
Programming**.
```{r data.date, cache=TRUE, echo=FALSE}
data.date <- format(Sys.Date(), "%a %b %d %Y")
```
## 1. Load Data
### Source
Data was obtained from the following [link][1] on `r data.date`.
Raw data is a .csv file containing the number of steps registered through five
minute intervals for a user during the months of October and November 2012.
It is structured so as follows:
- *steps*: number of step recorded for the given 5 minute interval
- *date*: date of the day
- *interval*: 5 minute interval of the record
[1]: https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip "link"
### Loading and Processing
Data was loaded into an R data.frame object.
```{r read.data, cache=TRUE}
data <- read.csv("activity.csv")
```
Since *interval* variable contains data as integer, an additional variable
(*time*) was created with the formated (24hr) start-time of the interval.
```{r interval.to.time, cache=TRUE}
data$time <- sprintf("%04d",data$interval)
data$time <- with(data, paste(substr(time, 1, 2),substr(time, 3, 4), sep=":"))
```
Find below the structure of the data:
```{r head.data}
head(data)
```
## 2. Steps per Day
For a first analysis of the number of steps the user recorded, the daily
step-count is calculated.
```{r daily.steps, cache=TRUE}
steps <- with(data, tapply(steps, date, sum, na.rm=TRUE))
data.daily <- data.frame(day=unique(data$date), steps=steps)
```
The following histogram shows the daily step-counts recorded throughout the two months of monitored data.
```{r daily.hist, fig.width=6, fig.height=6}
ggplot(data.daily, aes(x=steps)) +
geom_histogram(aes(fill = ..x..), colour = "black", binwidth = 700) +
scale_fill_gradient("#Steps", low = "darkred", high = "green") +
scale_y_continuous(breaks=c(2,4,6,8,10))
```
```{r daily.stats}
mean <- mean(data.daily$steps, na.rm=TRUE)
median <- median(data.daily$steps, na.rm=TRUE)
```
The daily-step count average is `r mean`, and the median `r median`.
## 3. Daily Activity
The second analysis is an average-day daily-activity time-series, in which
the mean steps for each interval is obtained (averaged over all observed days).
```{r activity, cache=TRUE}
steps <- with(data, tapply(steps, time, mean, na.rm=TRUE))
data.activity <- data.frame(time=strptime(unique(data$time),"%H:%M"),
steps=steps)
```
The obtained data is plotted in a time-series format as follows.
```{r act.ts, fig.width=6, fig.height=6}
ggplot(data.activity, aes(time,steps, group=1)) +
geom_line(aes(colour= ..y..), size = 1.5) +
scale_colour_gradient("#Steps", low = "darkred", high = "green") +
scale_x_datetime(breaks = date_breaks("2 hours"),
labels = date_format("%Hh"))
```
```{r act.max}
max <- format(subset(data.activity, steps == max(steps))$time, "%R")
```
The average-daily 5-minute interval with most activity count starts at `r max`.
## 4. Missing Values
```{r count.NA}
NAnum <- sum(is.na(data$steps))
```
The data has `r NAnum` missing observations (NA). For those values several
fill-in strategies may be applied:
- input the day average or median
- input the average or median for the specific interval
- input an interpolation between the previous and the following intervals
The ensuing code fills-in the missing values according to the first possible
strategy (daily-average for that interval).
```{r NA.fill, cache=TRUE}
# Interval daily-averages
int.avg <- data.frame(avg= data.activity$steps,interval=unique(data$interval))
# Merge with original data in auxiliary file
data.fill <- merge(data,int.avg, by='interval')
data.fill$steps[is.na(data.fill$steps)] <- data.fill$avg[is.na(data.fill$steps)]
```
```{r check.NA}
NAnum.new <- sum(is.na(data.fill$steps))
```
The new data has `r NAnum.new` missing observations.
### Recalculate Steps per Day
The steps per day analysis is performed over the new, complete data set.
```{r fill.daily, cache=TRUE, fig.width=6, fig.height=6}
steps.f <- with(data.fill, tapply(steps, date, sum))
data.f.daily <- data.frame(day=unique(data.fill$date), steps=steps.f)
# Plot histogram
ggplot(data.f.daily, aes(x=steps)) +
geom_histogram(aes(fill = ..x..), colour = "black", binwidth = 700) +
scale_fill_gradient("#Steps", low = "darkred", high = "green") +
scale_y_continuous(breaks=c(2,4,6,8,10))
```
```{r fill.daily.stats}
mean.f <- format(mean(data.f.daily$steps, na.rm=TRUE), scientific=FALSE)
median.f <- format(median(data.f.daily$steps, na.rm=TRUE), scientific=FALSE)
```
The new daily-step count average is `r mean.f`, and the median `r median.f`.
By means of this transformation, outlier (missing) values have been substituted
with an inference (a probable guess) of what most likely was the true value.
As shown in the histogram, and further evidenced in the new median and mean, the
new data is more centered. The fill-in of missing data has eliminated the
numerous zeros found in the first histogram, and an average value has been
used in there placed. Additionally, the median (being more robust than the
mean) was closer to the inferred value mean and median.
## 5. Weekdays vs. Weekends
The last analysis comprises a comparison between the activity on weekdays and
the activities on weekends.
In order to perform the analysis a factor variable is created in order to
analyse the differences between the two different daily activity time-series
plots.
```{r weekday.format}
weekend <- c("Saturday", "Sunday")
data.fill$weekend <- weekdays(strptime(data.fill$date,"%Y-%m-%d")) %in% weekend
```
### Daily activity: Weekday/Weekend
The same analysis carried out previously, now performed separately, now shows
the following average-day activity levels.
```{r weekday.activity, cache=TRUE, fig.width=6, fig.height=6}
# Weekday time-series
steps.wd <- with(subset(data.fill,weekend == FALSE),
tapply(steps, interval, mean, na.rm=TRUE))
data.activity.wd <- data.frame(time=strptime(unique(data$time),"%H:%M"),
steps=steps.wd, weekday = "weekday")
# Weekend time-series
steps.we <- with(subset(data.fill,weekend == TRUE),
tapply(steps, interval, mean, na.rm=TRUE))
data.activity.we <- data.frame(time=strptime(unique(data$time),"%H:%M"),
steps=steps.we, weekday = "weekend")
# Append both data frames
data.activity.f <- rbind(data.activity.wd,data.activity.we)
# Plot time-series
ggplot(data.activity.f, aes(time,steps, group=1)) +
geom_line(aes(colour= ..y..), size = 1.5) +
scale_colour_gradient("#Steps", low = "darkred", high = "green") +
facet_grid(weekday ~ .) +
scale_x_datetime(breaks = date_breaks("2 hours"),
labels = date_format("%Hh"))
```
The analysis shows lower levels of activity first thing in the weekdays (8 AM).
However during weekend mornings there is a higher average of activity. This is
consistent with weekday work schedule.
library(ggplot2)
library(scales)
data.date <- format(Sys.Date(), "%a %b %d %Y")
data <- read.csv("activity.csv")
getwd()
setwd("./..")
getwd
getwd()
setwd("./Reproducible Research/Assignment 1/RepData_PeerAssessment1/")
ls()
data <- read.csv("activity.csv")
data$time <- sprintf("%04d",data$interval)
data$time <- with(data, paste(substr(time, 1, 2),substr(time, 3, 4), sep=":"))
head(data)
steps <- with(data, tapply(steps, date, sum, na.rm=TRUE))
data.daily <- data.frame(day=unique(data$date), steps=steps)
gplot(data.daily, aes(x=steps)) +
geom_histogram(aes(fill = ..x..), colour = "black", binwidth = 700) +
scale_fill_gradient("#Steps", low = "darkred", high = "green") +
scale_y_continuous(breaks=c(2,4,6,8,10))
ggplot(data.daily, aes(x=steps)) +
geom_histogram(aes(fill = ..x..), colour = "black", binwidth = 700) +
scale_fill_gradient("#Steps", low = "darkred", high = "green") +
scale_y_continuous(breaks=c(2,4,6,8,10))
mean <- mean(data.daily$steps, na.rm=TRUE)
median <- median(data.daily$steps, na.rm=TRUE)
steps <- with(data, tapply(steps, time, mean, na.rm=TRUE))
data.activity <- data.frame(time=strptime(unique(data$time),"%H:%M"),
steps=steps)
ggplot(data.activity, aes(time,steps, group=1)) +
geom_line(aes(colour= ..y..), size = 1.5) +
scale_colour_gradient("#Steps", low = "darkred", high = "green") +
scale_x_datetime(breaks = date_breaks("2 hours"),
labels = date_format("%Hh"))
max <- format(subset(data.activity, steps == max(steps))$time, "%R")
NAnum <- sum(is.na(data$steps))
# Interval daily-averages
int.avg <- data.frame(avg= data.activity$steps,interval=unique(data$interval))
# Merge with original data in auxiliary file
data.fill <- merge(data,int.avg, by='interval')
data.fill$steps[is.na(data.fill$steps)] <- data.fill$avg[is.na(data.fill$steps)]
NAnum.new <- sum(is.na(data.fill$steps))
steps.f <- with(data.fill, tapply(steps, date, sum))
data.f.daily <- data.frame(day=unique(data.fill$date), steps=steps.f)
# Plot histogram
ggplot(data.f.daily, aes(x=steps)) +
geom_histogram(aes(fill = ..x..), colour = "black", binwidth = 700) +
scale_fill_gradient("#Steps", low = "darkred", high = "green") +
scale_y_continuous(breaks=c(2,4,6,8,10))
mean.f <- format(mean(data.f.daily$steps, na.rm=TRUE), scientific=FALSE)
median.f <- format(median(data.f.daily$steps, na.rm=TRUE), scientific=FALSE)
weekend <- c("Saturday", "Sunday")
data.fill$weekend <- weekdays(strptime(data.fill$date,"%Y-%m-%d")) %in% weekend
# Weekday time-series
steps.wd <- with(subset(data.fill,weekend == FALSE),
tapply(steps, interval, mean, na.rm=TRUE))
data.activity.wd <- data.frame(time=strptime(unique(data$time),"%H:%M"),
steps=steps.wd, weekday = "weekday")
# Weekend time-series
steps.we <- with(subset(data.fill,weekend == TRUE),
tapply(steps, interval, mean, na.rm=TRUE))
data.activity.we <- data.frame(time=strptime(unique(data$time),"%H:%M"),
steps=steps.we, weekday = "weekend")
# Append both data frames
data.activity.f <- rbind(data.activity.wd,data.activity.we)
# Plot time-series
ggplot(data.activity.f, aes(time,steps, group=1)) +
geom_line(aes(colour= ..y..), size = 1.5) +
scale_colour_gradient("#Steps", low = "darkred", high = "green") +
facet_grid(weekday ~ .) +
scale_x_datetime(breaks = date_breaks("2 hours"),
labels = date_format("%Hh"))
steps.wd <- with(subset(data.fill,weekend == FALSE),
tapply(steps, interval, mean, na.rm=TRUE))
data.activity.wd <- data.frame(time=strptime(unique(data$time),"%H:%M"),
steps=steps.wd, weekday = "weekday")
# Weekend time-series
steps.we <- with(subset(data.fill,weekend == TRUE),
tapply(steps, interval, mean, na.rm=TRUE))
data.activity.we <- data.frame(time=strptime(unique(data$time),"%H:%M"),
steps=steps.we, weekday = "weekend")
steps.we <- with(subset(data.fill,weekend == TRUE),
tapply(steps, interval, mean, na.rm=TRUE))
data.activity.we <- data.frame(time=strptime(unique(data$time),"%H:%M"),
steps=steps.we, weekday = "weekend")
data.activity.f <- rbind(data.activity.wd,data.activity.we)
steps
steps.we
steps.wd
steps.we <- with(subset(data.fill,weekend == TRUE),
tapply(steps, interval, mean, na.rm=TRUE))
steps.we
data.fill
subset(data.fill,weekend == TRUE)
data.fill$weekend <- weekdays(strptime(data.fill$date,"%Y-%m-%d")) %in% weekend
subset(data.fill,weekend == TRUE)
weekend
weekdays(strptime(data.fill$date,"%Y-%m-%d"))
Sys.setlocale("LC_TIME","Spanish Modern Sort")
Sys.setlocale("LC_TIME","English United States")
weekdays(strptime(data.fill$date,"%Y-%m-%d"))
Sys.setlocale("LC_TIME","English United States")
weekdays(Sys.Date()+0:6)
Sys.setlocale("LC_TIME", "English")
Sys.getlocale("LC_TIME")
Sys.setlocale("LC_TIME", "English")
